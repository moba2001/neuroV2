{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\version.py:58: UserWarning: This version of NengoDL has not been tested with your Nengo version (4.0.0). The latest fully supported version is 3.2.0.\n",
      "  warnings.warn(warnstr)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nengo\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tkinter as tk\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nengo_extras.data import one_hot_from_labels\n",
    "from nengo_extras.matplotlib import tile\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "import pickle\n",
    "import nengo_dl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nengo_dlNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached nengo_dl-3.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: jinja2>=2.10.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nengo_dl) (3.1.2)\n",
      "Requirement already satisfied: progressbar2>=3.39.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nengo_dl) (4.3.2)\n",
      "Requirement already satisfied: tensorflow>=2.3.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nengo_dl) (2.12.0)\n",
      "Requirement already satisfied: nengo>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nengo_dl) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nengo_dl) (1.23.5)\n",
      "Collecting tensorflow>=2.3.4\n",
      "  Using cached tensorflow-2.10.1-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nengo_dl) (23.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2>=2.10.1->nengo_dl) (2.1.1)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from progressbar2>=3.39.0->nengo_dl) (3.8.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (2.10.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (16.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (2.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (4.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (65.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (23.5.26)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (1.54.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (1.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (0.4.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.3.4->nengo_dl) (3.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.3.4->nengo_dl) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (2.20.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (2.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (0.2.8)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (1.26.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (3.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow>=2.3.4->nengo_dl) (3.2.2)\n",
      "Installing collected packages: tensorflow, nengo_dl\n",
      "Successfully installed nengo_dl-3.6.0 tensorflow-2.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --user nengo_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "import os\n",
    "from random import shuffle\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 120, 320)\n"
     ]
    }
   ],
   "source": [
    "input_width = 320\n",
    "input_height = 120 \n",
    "n_hid = 1000\n",
    "\n",
    "lookup = dict()\n",
    "reverselookup = dict()\n",
    "count = 0\n",
    "for j in os.listdir('./input/leapgestrecog/leapGestRecog/00/'):\n",
    "    if not j.startswith('.'): # If running this code locally, this is to \n",
    "                              # ensure you aren't reading in hidden folders\n",
    "        lookup[j] = count\n",
    "        reverselookup[count] = j\n",
    "        count = count + 1\n",
    "lookup\n",
    "\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "datacount = 0 # We'll use this to tally how many images are in our dataset\n",
    "for i in range(0, 10): # Loop over the ten top-level folders\n",
    "    for j in os.listdir('./input/leapgestrecog/leapGestRecog/0' + str(i) + '/'):\n",
    "        if not j.startswith('.'): # Again avoid hidden folders\n",
    "            count = 0 # To tally images of a given gesture\n",
    "            for k in os.listdir('./input/leapgestrecog/leapGestRecog/0' + \n",
    "                                str(i) + '/' + j + '/'):\n",
    "                                # Loop over the images\n",
    "                img = Image.open('./input/leapgestrecog/leapGestRecog/0' + \n",
    "                                 str(i) + '/' + j + '/' + k).convert('L')\n",
    "                                # Read in and convert to greyscale\n",
    "                img = img.resize((input_width, input_height))\n",
    "                arr = np.array(img)\n",
    "                x_data.append(arr) \n",
    "                count = count + 1\n",
    "            y_values = np.full((count, 1), lookup[j]) \n",
    "            y_data.append(y_values)\n",
    "            datacount = datacount + count\n",
    "x_data = np.array(x_data, dtype = 'float32')\n",
    "x_data = x_data / 255 * 2 - 1\n",
    "print(x_data.shape)\n",
    "#x_data = x_data.reshape(datacount, -1)\n",
    "\n",
    "y_data = np.array(y_data)\n",
    "y_data = y_data.reshape(datacount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 120, 320, 1)\n",
      "(20000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_data=to_categorical(y_data)\n",
    "x_data = x_data.reshape((datacount, input_height, input_width, 1))\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "x_train,x_further,y_train,y_further = train_test_split(x_data,y_data,test_size = 0.2, random_state=42)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (input_height,input_width,1)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(input_height, input_width, 1))\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    activation=tf.nn.relu,\n",
    ")(inp)\n",
    "\n",
    "avg_pool0 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(conv0)\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(avg_pool0)\n",
    "avg_pool1 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(avg_pool1)\n",
    "avg_pool2 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "# fully connected layer\n",
    "flatten0 = tf.keras.layers.Flatten()(avg_pool2)\n",
    "dense0 = tf.keras.layers.Dense(units=512,activation=tf.nn.relu)(flatten0)\n",
    "\n",
    "dense = tf.keras.layers.Dense(units=10,activation=\"softmax\")(dense0)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 120, 320, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 116, 316, 32)      832       \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 58, 158, 32)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 28, 78, 64)        18496     \n",
      "                                                                 \n",
      " average_pooling2d_7 (Averag  (None, 14, 39, 64)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 6, 19, 64)         36928     \n",
      "                                                                 \n",
      " average_pooling2d_8 (Averag  (None, 3, 9, 64)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 1728)              0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 512)               885248    \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 946,634\n",
      "Trainable params: 946,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "125/125 [==============================] - 95s 754ms/step - loss: 0.9316 - accuracy: 0.6834 - val_loss: 0.1351 - val_accuracy: 0.9630\n",
      "Epoch 2/7\n",
      "125/125 [==============================] - 93s 746ms/step - loss: 0.0557 - accuracy: 0.9866 - val_loss: 0.0240 - val_accuracy: 0.9920\n",
      "Epoch 3/7\n",
      "125/125 [==============================] - 94s 754ms/step - loss: 0.0166 - accuracy: 0.9966 - val_loss: 0.0106 - val_accuracy: 0.9975\n",
      "Epoch 4/7\n",
      "125/125 [==============================] - 92s 738ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "Epoch 5/7\n",
      "125/125 [==============================] - 92s 735ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 6/7\n",
      "125/125 [==============================] - 92s 735ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
      "Epoch 7/7\n",
      "125/125 [==============================] - 92s 734ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9990\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(x_train, y_train, epochs=7, batch_size=batch_size, verbose=1, validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr = 20\n",
    "ndl_model = nengo_dl.Converter(\n",
    "    model,\n",
    "    swap_activations={\n",
    "        tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "    scale_firing_rates=sfr,\n",
    "    synapse=0.005,\n",
    "    inference_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_cnn_nengo_pre.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tile the test images.\n",
    "def get_nengo_compatible_test_data_generator(batch_size=100, n_steps=30):\n",
    "  \"\"\"\n",
    "  Returns a test data generator of tiled (i.e. repeated) images.\n",
    "\n",
    "  Args:\n",
    "    batch_size <int>: Number of data elements in each batch.\n",
    "    n_steps <int>: Number of timesteps for which the test data has to\n",
    "                   be repeated.\n",
    "  \"\"\"\n",
    "  num_images = int(x_test.shape[0]/20)\n",
    "  # Flatten the images\n",
    "  reshaped_x_test = x_test.reshape((num_images, 1, -1))\n",
    "  # Tile/Repeat them for `n_steps` times.\n",
    "  tiled_x_test = np.tile(reshaped_x_test, (1, n_steps, 1))\n",
    "\n",
    "  for i in range(0, num_images, batch_size):\n",
    "    yield (tiled_x_test[i:i+batch_size], y_test[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probes for Input, first Conv, and the Output layers.\n",
    "ndl_mdl_inpt = ndl_model.inputs[inp] # Input layer is Layer 0.\n",
    "ndl_mdl_otpt = ndl_model.outputs[dense] # Output layer is last.\n",
    "with ndl_model.net:\n",
    "  nengo_dl.configure_settings(stateful=False) # Optimize simulation speed.\n",
    "  # Probe for the first Conv layer.\n",
    "  first_conv_probe = nengo.Probe(ndl_model.layers[conv0])\n",
    "  # Probe for penultimate dense layer.\n",
    "  penltmt_dense_probe = nengo.Probe(ndl_model.layers[dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 120, 320, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_nengo_compatible_test_data_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m ndl_mdl_otpt_cls_probs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# To store the true class labels and the temporal\u001b[39;00m\n\u001b[0;32m      7\u001b[0m                             \u001b[38;5;66;03m# class-probabilities output of the model.\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m test_batches \u001b[38;5;241m=\u001b[39m \u001b[43mget_nengo_compatible_test_data_generator\u001b[49m(\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size, n_steps \u001b[38;5;241m=\u001b[39m n_steps)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Run the simulation.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nengo_dl\u001b[38;5;241m.\u001b[39mSimulator(ndl_model\u001b[38;5;241m.\u001b[39mnet, minibatch_size\u001b[38;5;241m=\u001b[39mbatch_size) \u001b[38;5;28;01mas\u001b[39;00m sim:\n\u001b[0;32m     14\u001b[0m   \u001b[38;5;66;03m# Predict on each batch.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_nengo_compatible_test_data_generator' is not defined"
     ]
    }
   ],
   "source": [
    "n_steps = 30 # Number of timesteps\n",
    "batch_size = 100\n",
    "collect_spikes_output = True\n",
    "ndl_mdl_spikes = [] # To store the spike outputs of the first Conv layer and the\n",
    "                    # penultimate dense layer whose probes we defined earlier.\n",
    "ndl_mdl_otpt_cls_probs = [] # To store the true class labels and the temporal\n",
    "                            # class-probabilities output of the model.\n",
    "\n",
    "test_batches = get_nengo_compatible_test_data_generator(\n",
    "    batch_size=batch_size, n_steps = n_steps)\n",
    "\n",
    "# Run the simulation.\n",
    "with nengo_dl.Simulator(ndl_model.net, minibatch_size=batch_size) as sim:\n",
    "  # Predict on each batch.\n",
    "  for batch in test_batches:\n",
    "    sim_data = sim.predict_on_batch({ndl_mdl_inpt: batch[0]})\n",
    "    for y_true, y_pred in zip(batch[1], sim_data[ndl_mdl_otpt]):\n",
    "      # Note that y_true is an array of shape (10,) and y_pred is a matrix of\n",
    "      # shape (n_steps, 10) where 10 is the number of classes in CIFAR-10 dataset.\n",
    "      ndl_mdl_otpt_cls_probs.append((y_true, y_pred))\n",
    "\n",
    "    # Collect the spikes if required.\n",
    "    if collect_spikes_output:\n",
    "      for i in range(batch_size): # Collecting spikes for each image in first batch.\n",
    "        ndl_mdl_spikes.append({\n",
    "          first_conv_probe.obj.ensemble.label: sim_data[first_conv_probe][i],\n",
    "          penltmt_dense_probe.obj.ensemble.label: sim_data[penltmt_dense_probe][i]\n",
    "        })\n",
    "      # Not collecting the spikes for rest batches to save memory.\n",
    "      collect_spikes_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(test_batches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "temporal_cls_probs = [] # To store the temporal class-probabilities of each test image.\n",
    "for y_true, y_pred in ndl_mdl_otpt_cls_probs:\n",
    "  # Pick the spiking network's last time-step output, therefore -1 in y_pred.\n",
    "  temporal_cls_probs.append(y_pred)\n",
    "  if np.argmax(y_true) == np.argmax(y_pred[-1]):\n",
    "    acc += 1\n",
    "\n",
    "print(\"Spiking network prediction accuracy: %s %%\" % (acc * 100/ x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probability(ax, true_cls, pred_cls, clss_probs, num_clss=10):\n",
    "  \"\"\"\n",
    "  Plots the temporal variability in predicted class-probabilities.\n",
    "\n",
    "  Args:\n",
    "    ax <matplotlib.axes._subplots.AxesSubplot>: Subplot pane.\n",
    "    true_cls <int>: The true class of the test image.\n",
    "    pred_cls <int>: The predicted class of the test image from spiking network.\n",
    "    clss_probs <numpy.ndarray>: The predicted class probabilities at each\n",
    "                                timestep. Shape: (n_steps, num_clss).\n",
    "  \"\"\"\n",
    "  ax.set_title(\"True Class: %s, Pred Class: %s\" % (true_cls, pred_cls))\n",
    "  ax.plot(clss_probs)\n",
    "  ax.legend([str(j) for j in range(num_clss)], loc=\"upper left\")\n",
    "  ax.set_xlabel(\"Time in $ms$\")\n",
    "  ax.set_ylabel(\"Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8), facecolor=\"#00FFFF\")\n",
    "\n",
    "# Plot for the test image at index 0.\n",
    "plot_probability(\n",
    "    axs[0],\n",
    "    np.argmax(y_test[0]),\n",
    "    np.argmax(temporal_cls_probs[0][-1]), # Last timestep's probability scores.\n",
    "    temporal_cls_probs[0]\n",
    ")\n",
    "\n",
    "# Plot for the test image at index 19.\n",
    "plot_probability(\n",
    "    axs[1],\n",
    "    np.argmax(y_test[19]),\n",
    "    np.argmax(temporal_cls_probs[19][-1]), # Last timestep's probability scores.\n",
    "    temporal_cls_probs[19]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST VERSUCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 120, 320, 1)\n",
      "(400, 120, 320, 10)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "input_15 data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnengo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRectifiedLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[69], line 47\u001b[0m, in \u001b[0;36mrun_network\u001b[1;34m(activation, n_steps, scale_firing_rates, synapse, n_test)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# build network, load in trained weights, run inference on test images\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nengo_dl\u001b[38;5;241m.\u001b[39mSimulator(\n\u001b[0;32m     44\u001b[0m     nengo_converter\u001b[38;5;241m.\u001b[39mnet, minibatch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     45\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m nengo_sim:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#nengo_sim.load_params(params_file)\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnengo_sim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mnengo_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtiled_test_images\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# compute accuracy on test data, using output of network on\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# last timestep\u001b[39;00m\n\u001b[0;32m     51\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(data[nengo_output][:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\nengo\\utils\\magic.py:184\u001b[0m, in \u001b[0;36mBoundFunctionWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper(wrapped, instance, args, kwargs)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:63\u001b[0m, in \u001b[0;36mrequire_open\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SimulatorClosed(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after simulator is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:669\u001b[0m, in \u001b[0;36mSimulator.predict\u001b[1;34m(self, x, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;129m@require_open\u001b[39m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;129m@fill_docs\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstateful\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stateful\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;124;03m    Generate output predictions for the input samples.\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m        Output values from all the Probes in the network.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_keras(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m=\u001b[39mx, n_steps\u001b[38;5;241m=\u001b[39mn_steps, stateful\u001b[38;5;241m=\u001b[39mstateful, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    671\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\nengo\\utils\\magic.py:184\u001b[0m, in \u001b[0;36mBoundFunctionWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper(wrapped, instance, args, kwargs)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:46\u001b[0m, in \u001b[0;36mwith_self\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(instance\u001b[38;5;241m.\u001b[39mtensor_graph\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m---> 46\u001b[0m         output \u001b[38;5;241m=\u001b[39m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mset_floatx(keras_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:953\u001b[0m, in \u001b[0;36mSimulator._call_keras\u001b[1;34m(self, func_type, x, y, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# TODO: apply standardize/generate/check data to generator somehow\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# maybe move it into a callback where the generated data is available?\u001b[39;00m\n\u001b[0;32m    952\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_inputs(x, n_steps\u001b[38;5;241m=\u001b[39mn_steps)\n\u001b[1;32m--> 953\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminibatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_batch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    960\u001b[0m     input_steps \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:1929\u001b[0m, in \u001b[0;36mSimulator._check_data\u001b[1;34m(self, data, batch_size, n_steps, nodes)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;66;03m# generic shape checks\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1929\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have rank 3 (batch_size, n_steps, dimensions), found rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1931\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1932\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1933\u001b[0m     )\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch_size:\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\n\u001b[0;32m   1936\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size of data (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) less than Simulator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1937\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`minibatch_size` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1938\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1939\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: input_15 data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4"
     ]
    }
   ],
   "source": [
    "run_network(activation=nengo.RectifiedLinear(), n_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tile the test images.\n",
    "def get_nengo_compatible_test_data_generator(batch_size=100, n_steps=30):\n",
    "  \"\"\"\n",
    "  Returns a test data generator of tiled (i.e. repeated) images.\n",
    "\n",
    "  Args:\n",
    "    batch_size <int>: Number of data elements in each batch.\n",
    "    n_steps <int>: Number of timesteps for which the test data has to\n",
    "                   be repeated.\n",
    "  \"\"\"\n",
    "  num_images = x_test.shape[0]\n",
    "  # Flatten the images\n",
    "  reshaped_x_test = x_test.reshape((num_images, 1, -1))\n",
    "  # Tile/Repeat them for `n_steps` times.\n",
    "  tiled_x_test = np.tile(reshaped_x_test, (1, n_steps, 1))\n",
    "\n",
    "  for i in range(0, num_images, batch_size):\n",
    "    yield (tiled_x_test[i:i+batch_size], y_test[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probes for Input, first Conv, and the Output layers.\n",
    "ndl_mdl_inpt = ndl_model.inputs[layer_objs_lst[0]] # Input layer is Layer 0.\n",
    "ndl_mdl_otpt = ndl_model.outputs[layer_objs_lst[-1]] # Output layer is last.\n",
    "with ndl_model.net:\n",
    "  nengo_dl.configure_settings(stateful=False) # Optimize simulation speed.\n",
    "  # Probe for the first Conv layer.\n",
    "  first_conv_probe = nengo.Probe(ndl_model.layers[layer_objs_lst[1]])\n",
    "  # Probe for penultimate dense layer.\n",
    "  penltmt_dense_probe = nengo.Probe(ndl_model.layers[layer_objs_lst[-2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden noch normale neuronen trainiert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|#                     Building network (2%)                     | ETA: 0:02:48\n",
      "|#                     Building network (2%)                     | ETA: 0:02:50\n",
      "|#                     Building network (2%)                     | ETA: 0:02:52\n",
      "|#                     Building network (2%)                     | ETA: 0:02:54\n",
      "|#                     Building network (2%)                     | ETA: 0:02:56\n",
      "|#                     Building network (2%)                     | ETA: 0:02:59\n",
      "|#                     Building network (2%)                     | ETA: 0:03:01\n",
      "|#                     Building network (2%)                     | ETA: 0:03:03\n",
      "|#                     Building network (2%)                     | ETA: 0:03:05\n",
      "|#                     Building network (2%)                     | ETA: 0:03:07\n",
      "|#                     Building network (2%)                     | ETA: 0:03:09\n",
      "|#                     Building network (2%)                     | ETA: 0:03:11\n",
      "|#                     Building network (2%)                     | ETA: 0:03:13\n",
      "|#                     Building network (2%)                     | ETA: 0:03:15\n",
      "|#                     Building network (2%)                     | ETA: 0:03:18\n",
      "|#                     Building network (2%)                     | ETA: 0:03:20\n",
      "|#                     Building network (2%)                     | ETA: 0:03:22\n",
      "|#                     Building network (2%)                     | ETA: 0:03:24\n",
      "|#                     Building network (2%)                     | ETA: 0:03:26\n",
      "|#                     Building network (2%)                     | ETA: 0:03:28\n",
      "|#                     Building network (2%)                     | ETA: 0:03:30\n",
      "|#                     Building network (2%)                     | ETA: 0:03:32\n",
      "|#                     Building network (2%)                     | ETA: 0:03:35\n",
      "|#                     Building network (2%)                     | ETA: 0:03:37\n",
      "|#                     Building network (2%)                     | ETA: 0:03:39\n",
      "|#                     Building network (2%)                     | ETA: 0:03:41\n",
      "|#                     Building network (2%)                     | ETA: 0:03:43\n",
      "|#                     Building network (2%)                     | ETA: 0:03:45\n",
      "|#                     Building network (2%)                     | ETA: 0:03:47\n",
      "|#                     Building network (2%)                     | ETA: 0:03:49\n",
      "|#                     Building network (2%)                     | ETA: 0:03:52\n",
      "|#                     Building network (2%)                     | ETA: 0:03:54\n",
      "|#                     Building network (2%)                     | ETA: 0:03:56\n",
      "|#                     Building network (2%)                     | ETA: 0:03:58\n",
      "|#                     Building network (2%)                     | ETA: 0:04:00\n",
      "|#                     Building network (2%)                     | ETA: 0:04:02\n",
      "|#                     Building network (2%)                     | ETA: 0:04:04\n",
      "|#                     Building network (2%)                     | ETA: 0:04:06\n",
      "|#                     Building network (2%)                     | ETA: 0:04:08\n",
      "|###                   Building network (5%)                     | ETA: 0:02:01\n",
      "|###                   Building network (5%)                     | ETA: 0:02:02\n",
      "|###                   Building network (5%)                     | ETA: 0:02:03\n",
      "|###                   Building network (5%)                     | ETA: 0:02:04\n",
      "|###                   Building network (5%)                     | ETA: 0:02:05\n",
      "|###                   Building network (5%)                     | ETA: 0:02:06\n",
      "|###                   Building network (5%)                     | ETA: 0:02:08\n",
      "|###                   Building network (5%)                     | ETA: 0:02:09\n",
      "|###                   Building network (5%)                     | ETA: 0:02:10\n",
      "|###                   Building network (5%)                     | ETA: 0:02:11\n",
      "|###                   Building network (5%)                     | ETA: 0:02:12\n",
      "|###                   Building network (5%)                     | ETA: 0:02:13\n",
      "|###                   Building network (5%)                     | ETA: 0:02:14\n",
      "|###                   Building network (5%)                     | ETA: 0:02:15\n",
      "|#####                 Building network (8%)                     | ETA: 0:01:28\n",
      "|#####                 Building network (8%)                     | ETA: 0:01:28\n",
      "|#####                 Building network (8%)                     | ETA: 0:01:29\n",
      "|#####################Building network (85%)###########          | ETA: 0:00:01\n",
      "|#####################Building network (85%)###########          | ETA: 0:00:01\n",
      "|#####################Building network (85%)###########          | ETA: 0:00:01\n",
      "Build finished in 0:00:08\n",
      "|#                         Optimizing graph                           | 0:00:00\n",
      "|#             Optimizing graph: operator simplificaton               | 0:00:00\n",
      "Optimizing graph: operator simplificaton finished in 0:00:00\n",
      "|#                Optimizing graph: merging operators                 | 0:00:00\n",
      "Optimizing graph: merging operators finished in 0:00:00\n",
      "|#                Optimizing graph: ordering signals                  | 0:00:00\n",
      "Optimizing graph: ordering signals finished in 0:00:00\n",
      "|#                Optimizing graph: creating signals                  | 0:00:00\n",
      "Optimizing graph: creating signals finished in 0:00:00\n",
      "Optimization finished in 0:00:00\n",
      "|#                        Constructing graph                          | 0:00:00\n",
      "| #                       Constructing graph                          | 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "|############Constructing graph: pre-build stage (35%)           | ETA: 0:00:00\n",
      "|  #                      Constructing graph                          | 0:00:00\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|######        Constructing graph: build stage (10%)             | ETA: 0:00:04\n",
      "|############# Constructing graph: build stage (21%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (75%)             | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "|         #               Constructing graph                          | 0:00:00\n",
      "Construction finished in 0:00:00\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "input_10 data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nengo_dl\u001b[38;5;241m.\u001b[39mSimulator(converter\u001b[38;5;241m.\u001b[39mnet, minibatch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m sim:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# run training\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     sim\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      6\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m      7\u001b[0m         loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      8\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39msparse_categorical_accuracy],\n\u001b[0;32m      9\u001b[0m     )\n\u001b[1;32m---> 10\u001b[0m     \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43minp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43minp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_validate\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validate\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# save the parameters to file\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     sim\u001b[38;5;241m.\u001b[39msave_params(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./keras_to_snn_params\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\nengo\\utils\\magic.py:184\u001b[0m, in \u001b[0;36mBoundFunctionWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper(wrapped, instance, args, kwargs)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:63\u001b[0m, in \u001b[0;36mrequire_open\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SimulatorClosed(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after simulator is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:847\u001b[0m, in \u001b[0;36mSimulator.fit\u001b[1;34m(self, x, y, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m    845\u001b[0m x_val \u001b[38;5;241m=\u001b[39m validation_data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    846\u001b[0m x_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_inputs(x_val, n_steps\u001b[38;5;241m=\u001b[39mn_steps)\n\u001b[1;32m--> 847\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    849\u001b[0m y_val \u001b[38;5;241m=\u001b[39m validation_data[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    850\u001b[0m y_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_standardize_data(y_val, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mprobes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:1929\u001b[0m, in \u001b[0;36mSimulator._check_data\u001b[1;34m(self, data, batch_size, n_steps, nodes)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;66;03m# generic shape checks\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1929\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have rank 3 (batch_size, n_steps, dimensions), found rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1931\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1932\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1933\u001b[0m     )\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch_size:\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\n\u001b[0;32m   1936\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size of data (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) less than Simulator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1937\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`minibatch_size` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1938\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1939\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: input_10 data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
