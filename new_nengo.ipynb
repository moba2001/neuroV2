{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\version.py:58: UserWarning: This version of NengoDL has not been tested with your Nengo version (4.0.0). The latest fully supported version is 3.2.0.\n",
      "  warnings.warn(warnstr)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nengo\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tkinter as tk\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nengo_extras.data import one_hot_from_labels\n",
    "from nengo_extras.matplotlib import tile\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "import pickle\n",
    "import nengo_dl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "import os\n",
    "from random import shuffle\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 120, 320)\n"
     ]
    }
   ],
   "source": [
    "input_width = 320\n",
    "input_height = 120 \n",
    "n_hid = 1000\n",
    "\n",
    "lookup = dict()\n",
    "reverselookup = dict()\n",
    "count = 0\n",
    "for j in os.listdir('./input/leapgestrecog/leapGestRecog/00/'):\n",
    "    if not j.startswith('.'): # If running this code locally, this is to \n",
    "                              # ensure you aren't reading in hidden folders\n",
    "        lookup[j] = count\n",
    "        reverselookup[count] = j\n",
    "        count = count + 1\n",
    "lookup\n",
    "\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "datacount = 0 # We'll use this to tally how many images are in our dataset\n",
    "for i in range(0, 10): # Loop over the ten top-level folders\n",
    "    for j in os.listdir('./input/leapgestrecog/leapGestRecog/0' + str(i) + '/'):\n",
    "        if not j.startswith('.'): # Again avoid hidden folders\n",
    "            count = 0 # To tally images of a given gesture\n",
    "            for k in os.listdir('./input/leapgestrecog/leapGestRecog/0' + \n",
    "                                str(i) + '/' + j + '/'):\n",
    "                                # Loop over the images\n",
    "                img = Image.open('./input/leapgestrecog/leapGestRecog/0' + \n",
    "                                 str(i) + '/' + j + '/' + k).convert('L')\n",
    "                                # Read in and convert to greyscale\n",
    "                img = img.resize((input_width, input_height))\n",
    "                arr = np.array(img)\n",
    "                x_data.append(arr) \n",
    "                count = count + 1\n",
    "            y_values = np.full((count, 1), lookup[j]) \n",
    "            y_data.append(y_values)\n",
    "            datacount = datacount + count\n",
    "x_data = np.array(x_data, dtype = 'float32')\n",
    "x_data = x_data / 255 * 2 - 1\n",
    "print(x_data.shape)\n",
    "#x_data = x_data.reshape(datacount, -1)\n",
    "\n",
    "y_data = np.array(y_data)\n",
    "y_data = y_data.reshape(datacount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.reshape((x_data.shape[0], 1, -1))\n",
    "y_data = y_data.reshape((y_data.shape[0], 1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_further,y_train,y_further = train_test_split(x_data,y_data,test_size = 0.2, random_state=42)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1, 38400)\n",
      "(20000, 1, 10)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(input_height, input_width, 1))\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    activation=tf.nn.relu,\n",
    ")(inp)\n",
    "\n",
    "avg_pool0 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(conv0)\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(avg_pool0)\n",
    "avg_pool1 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(avg_pool1)\n",
    "avg_pool2 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "# fully connected layer\n",
    "flatten0 = tf.keras.layers.Flatten()(avg_pool2)\n",
    "dense0 = tf.keras.layers.Dense(units=30,activation=tf.nn.relu)(flatten0)\n",
    "\n",
    "dense = tf.keras.layers.Dense(units=10,activation=\"softmax\")(dense0)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\converter.py:583: UserWarning: Activation type <function softmax at 0x000001C778182050> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "converter = nengo_dl.Converter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:456: UserWarning: No GPU support detected. See https://www.nengo.ai/nengo-dl/installation.html#installing-tensorflow for instructions on setting up TensorFlow with GPU support.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|#                     Building network (3%)                     | ETA: 0:02:47\n",
      "|#                     Building network (3%)                     | ETA: 0:02:49\n",
      "|#                     Building network (3%)                     | ETA: 0:02:51\n",
      "|#                     Building network (3%)                     | ETA: 0:02:53\n",
      "|#                     Building network (3%)                     | ETA: 0:02:55\n",
      "|#                     Building network (3%)                     | ETA: 0:02:57\n",
      "|#                     Building network (3%)                     | ETA: 0:02:59\n",
      "|#                     Building network (3%)                     | ETA: 0:03:01\n",
      "|#                     Building network (3%)                     | ETA: 0:03:03\n",
      "|#####################Building network (51%)                     | ETA: 0:00:05\n",
      "Build finished in 0:00:05\n",
      "|#                         Optimizing graph                           | 0:00:00\n",
      "|#             Optimizing graph: operator simplificaton               | 0:00:00\n",
      "Optimizing graph: operator simplificaton finished in 0:00:00\n",
      "|#                Optimizing graph: merging operators                 | 0:00:00\n",
      "Optimizing graph: merging operators finished in 0:00:00\n",
      "|#                Optimizing graph: ordering signals                  | 0:00:00\n",
      "Optimizing graph: ordering signals finished in 0:00:00\n",
      "|#                Optimizing graph: creating signals                  | 0:00:00\n",
      "Optimizing graph: creating signals finished in 0:00:00\n",
      "Optimization finished in 0:00:00\n",
      "|#                        Constructing graph                          | 0:00:00\n",
      "| #                       Constructing graph                          | 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "|######      Constructing graph: pre-build stage (10%)           | ETA: 0:00:00\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|   #                     Constructing graph                          | 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|##            Constructing graph: build stage (3%)              | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (30%)             | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|     #                   Constructing graph                          | 0:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "Construction finished in 0:00:00\n",
      "Epoch 1/2\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|##            Constructing graph: build stage (3%)              | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (30%)             | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|##            Constructing graph: build stage (3%)              | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (30%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (90%)######       | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "80/80 [==============================] - ETA: 0s - loss: 1.9841 - probe_loss: 1.9841 - probe_sparse_categorical_accuracy: 0.4811 |           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "|######      Constructing graph: pre-build stage (10%)           | ETA: 0:00:00\n",
      "|######      Constructing graph: pre-build stage (10%)           | ETA: 0:00:01\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|############  Constructing graph: build stage (20%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (63%)             | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1668, in test_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 143, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 700, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 962, in sparse_categorical_matches\n        y_true = tf.squeeze(y_true, [-1])\n\n    ValueError: Can not squeeze dim[2], expected a dimension of 1, got 38400 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](IteratorGetNext:6)' with input shapes: [200,1,38400].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nengo_dl\u001b[38;5;241m.\u001b[39mSimulator(converter\u001b[38;5;241m.\u001b[39mnet, minibatch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m sim:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# run training\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     sim\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      6\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m      7\u001b[0m         loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      8\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39msparse_categorical_accuracy],\n\u001b[0;32m      9\u001b[0m     )\n\u001b[1;32m---> 10\u001b[0m     \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43minp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43minp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# save the parameters to file\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     sim\u001b[38;5;241m.\u001b[39msave_params(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./keras_to_snn_params\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\nengo\\utils\\magic.py:184\u001b[0m, in \u001b[0;36mBoundFunctionWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper(wrapped, instance, args, kwargs)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:63\u001b[0m, in \u001b[0;36mrequire_open\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SimulatorClosed(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after simulator is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:858\u001b[0m, in \u001b[0;36mSimulator.fit\u001b[1;34m(self, x, y, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    856\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_data\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (x_val, y_val, validation_data[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 858\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_keras(\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, n_steps\u001b[38;5;241m=\u001b[39mn_steps, stateful\u001b[38;5;241m=\u001b[39mstateful, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    860\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\nengo\\utils\\magic.py:184\u001b[0m, in \u001b[0;36mBoundFunctionWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper(wrapped, instance, args, kwargs)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:46\u001b[0m, in \u001b[0;36mwith_self\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(instance\u001b[38;5;241m.\u001b[39mtensor_graph\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m---> 46\u001b[0m         output \u001b[38;5;241m=\u001b[39m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mset_floatx(keras_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nengo_dl\\simulator.py:1022\u001b[0m, in \u001b[0;36mSimulator._call_keras\u001b[1;34m(self, func_type, x, y, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1020\u001b[0m     func_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1022\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model, func_type)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_args)\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# update n_steps/time\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stateful:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filevkdzpea0.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1668, in test_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 143, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 700, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 962, in sparse_categorical_matches\n        y_true = tf.squeeze(y_true, [-1])\n\n    ValueError: Can not squeeze dim[2], expected a dimension of 1, got 38400 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](IteratorGetNext:6)' with input shapes: [200,1,38400].\n"
     ]
    }
   ],
   "source": [
    "do_training = True\n",
    "if do_training:\n",
    "    with nengo_dl.Simulator(converter.net, minibatch_size=200) as sim:\n",
    "        # run training\n",
    "        sim.compile(\n",
    "            optimizer=tf.optimizers.Adam(0.001),\n",
    "            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[tf.metrics.sparse_categorical_accuracy],\n",
    "        )\n",
    "        sim.fit(\n",
    "            {converter.inputs[inp]: x_train},\n",
    "            {converter.outputs[dense]: y_train},\n",
    "            validation_data=(\n",
    "                {converter.inputs[inp]: x_test},\n",
    "                {converter.outputs[dense]: x_test},\n",
    "            ),\n",
    "            epochs=2,\n",
    "        )\n",
    "\n",
    "        # save the parameters to file\n",
    "        sim.save_params(\"./keras_to_snn_params\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
